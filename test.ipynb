{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/fv77t6m12w10lpgqfwccmxjh0000gn/T/ipykernel_18961/2289009914.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2:3b\")  # e.g., \"llama2\", \"mistral\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is a branch of physics that describes the behavior of matter and energy at an atomic and subatomic level, where particles can exist in multiple states and locations simultaneously until observed or measured. At this scale, the principles of classical physics no longer apply, and phenomena such as wave-particle duality, superposition, and entanglement govern the behavior of quantum systems. The strange and counterintuitive nature of quantum mechanics has led to a deep understanding of the fundamental laws governing reality, but it also presents significant challenges for our everyday experience and perception of the world.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Initialize Ollama\n",
    "llm = Ollama(model=\"llama3.2:3b\")  # e.g., \"llama2\", \"mistral\"\n",
    "\n",
    "# Generate text\n",
    "response = llm.invoke(\"Explain quantum mechanics in 3 sentences.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/fv77t6m12w10lpgqfwccmxjh0000gn/T/ipykernel_18961/3325011811.py:4: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  name = llm(\"I want to open a Indian Restaurant please suggest me only one fancy name for the same\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a fancy name suggestion for your Indian restaurant:\n",
      "\n",
      "\"Maharaja's Oasis\"\n",
      "\n",
      "This name evokes the rich and regal heritage of India, with \"Maharaja\" meaning \"great king\" in Hindi. The word \"Oasis\" implies a luxurious and exotic destination, suggesting a refined dining experience.\n",
      "\n",
      "Let me know if you'd like more suggestions!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "name = llm(\"I want to open a Indian Restaurant please suggest me only one fancy name for the same\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a Mexican Restaurant. Please suggest me only one fancy name for the same, no explanation just name'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_res_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a {cuisine} Restaurant. Please suggest me only one fancy name for the same, no explanation just name\"\n",
    ")\n",
    "prompt_template_res_name.format(cuisine=\"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/fv77t6m12w10lpgqfwccmxjh0000gn/T/ipykernel_18038/3616258276.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template_res_name)\n",
      "/var/folders/60/fv77t6m12w10lpgqfwccmxjh0000gn/T/ipykernel_18038/3616258276.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"American\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Liberty Bistro\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_res_name)\n",
    "chain.run(\"American\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "\n",
    "prompt_template_res_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a {cuisine} Restaurant. Please suggest me only one fancy name for the same, no explanation just name\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm,prompt=prompt_template_res_name)\n",
    "\n",
    "prompt_template_menu_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template= \"Suggest me some menu items for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_menu_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some menu item suggestions for \"Liberty's Table\":\n",
      "\n",
      "Patriot's Burger (grass-fed beef, American cheese, bacon, and BBQ sauce), Liberty Bell Chicken Wings (spicy buffalo wings with blue cheese dressing), Revolutionary Ribeye Steak (grilled ribeye with roasted garlic mashed potatoes), Freedom Fries (crinkle-cut fries with truffle aioli), Constitution Chicken Salad (mixed greens, grilled chicken, cherry tomatoes, cucumber, and balsamic vinaigrette), Statue of Liberty Shrimp (garlic butter shrimp with lemon-herb quinoa), Founding Fathers' Fish & Chips (beer-battered cod with malt vinegar tartar sauce), Independence Day BBQ Ribs (slow-cooked pork ribs with coleslaw and cornbread), American Dream Meatloaf (homestyle meatloaf with ketchup glaze and roasted carrots).\n",
      "\n",
      "Note: These menu items are inspired by American themes and symbols, but feel free to modify or adjust them according to your taste preferences.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain,food_items_chain])\n",
    "response = chain.run(\"American\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "\n",
    "prompt_template_res_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a {cuisine} Restaurant. Please suggest me only one fancy name for the same, no explanation just name\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm,prompt=prompt_template_res_name, output_key = \"restaurant_name\")\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "prompt_template_menu_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template= \"Suggest me some menu items for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_menu_items, output_key = \"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/fv77t6m12w10lpgqfwccmxjh0000gn/T/ipykernel_18038/3749435954.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({'cuisine':'Arabian'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabian',\n",
       " 'restaurant_name': '\"Souk Al-Rahma\"',\n",
       " 'menu_items': 'Here are some suggested menu items for \"Souk Al-Rahma\" in a comma-separated list:\\n\\nTraditional Middle Eastern dishes like Shawarma, Machboos (a rice dish with meat and spices), Kibbeh (crunchy fried balls filled with ground meat or vegetables), Harees (slow-cooked wheat porridge), Maqluba (upside-down roasted chicken and vegetables), Ful Medames (stewed fava beans with garlic and lemon), Musakhan (chicken and onions in a bed of sumac and thyme), Falafel, Grilled halloumi cheese, Umm Ali (a sweet dessert made from puff pastry, milk, and nuts).\\n\\nPlease note that the menu items may vary based on regional and personal preferences.\\n\\nAlso, I would like to suggest some drinks:\\n\\nTea with cardamom or mint leaves\\nCoffee with cardamom or sugar\\nFresh juices (orange, lemon, or grapefruit)\\nHibiscus tea'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain,food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name','menu_items']\n",
    ")\n",
    "chain({'cuisine':'Arabian'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
