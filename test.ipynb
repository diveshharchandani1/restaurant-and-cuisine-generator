{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/60/fv77t6m12w10lpgqfwccmxjh0000gn/T/ipykernel_26316/2289009914.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2:3b\")  # e.g., \"llama2\", \"mistral\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is a branch of physics that describes the behavior of matter and energy at an atomic and subatomic level, where particles can exist in multiple states simultaneously and be connected across vast distances through entanglement. The principles of wave-particle duality, superposition, and uncertainty govern this realm, making it fundamentally different from classical mechanics. Quantum mechanics has been successfully applied to explain phenomena such as quantum tunneling, radioactive decay, and the properties of solids and liquids at the atomic level.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Initialize Ollama\n",
    "llm = Ollama(model=\"llama3.2:3b\")  # e.g., \"llama2\", \"mistral\"\n",
    "\n",
    "# Generate text\n",
    "response = llm.invoke(\"Explain quantum mechanics in 3 sentences.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a fancy name suggestion for your Indian restaurant:\n",
      "\n",
      "\"Maharaja's Haven\"\n",
      "\n",
      "This name evokes a sense of luxury and sophistication, suggesting a regal and indulgent dining experience. \"Maharaja\" is a title given to an Indian king or ruler, adding a touch of authenticity and cultural heritage. The word \"Haven\" implies a welcoming and cozy atmosphere, inviting customers to indulge in the rich flavors and aromas of Indian cuisine.\n",
      "\n",
      "What do you think?\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "name = llm(\"I want to open a Indian Restaurant please suggest me only one fancy name for the same\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a Mexican Restaurant. Please suggest me only one fancy name for the same, no explanation just name'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_res_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a {cuisine} Restaurant. Please suggest me only one fancy name for the same, no explanation just name\"\n",
    ")\n",
    "prompt_template_res_name.format(cuisine=\"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Liberty Eats\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_res_name)\n",
    "chain.run(\"American\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "\n",
    "prompt_template_res_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a {cuisine} Restaurant. Please suggest me only one fancy name for the same, no explanation just name\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm,prompt=prompt_template_res_name)\n",
    "\n",
    "prompt_template_menu_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template= \"Suggest me some menu items for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_menu_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some menu item suggestions for \"Liberty's Table\" in a comma-separated list:\n",
      "\n",
      "\"Classic American Fare with a Twist - Apple Pie Grilled Cheese, Southern Belle Sliders, Philly Cheesesteak Quesadilla, Bourbon-Glazed BBQ Ribs, New England Clam Chowder Cup, Liberty Bell Burger, Star-Spangled Salad (with mixed greens, cherry tomatoes, cucumber, and balsamic vinaigrette), Freedom Fries (topped with cheddar cheese, bacon bits, and scallions), Yankee Doodle Dandy Chicken Wings (with a side of spicy BBQ sauce).\"\n",
      "\n",
      "Let me know if you want me to suggest more items or make any changes!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain,food_items_chain])\n",
    "response = chain.run(\"American\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "\n",
    "prompt_template_res_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template= \"I want to open a {cuisine} Restaurant. Please suggest me only one fancy name for the same, no explanation just name\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm,prompt=prompt_template_res_name, output_key = \"restaurant_name\")\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:3b\", temperature=0.7)\n",
    "prompt_template_menu_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template= \"Suggest me some menu items for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_menu_items, output_key = \"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabian',\n",
       " 'restaurant_name': '\"Al-Rasoul\"',\n",
       " 'menu_items': 'I\\'d be happy to help you with some menu item suggestions for \"Al-Rasoul\"! Since I don\\'t have specific information about the restaurant or cuisine, I\\'ll provide some general Middle Eastern-inspired dishes that might fit well with an Arabic name like Al-Rasoul. Here\\'s a list of menu items:\\n\\nShawarma wraps, falafel plates, hummus platters, tabbouleh salads, grilled kebabs, machboos rice bowls, kibbeh patties, gormeh sabzi stews, baba ganoush dips, and baklava desserts.\\n\\nPlease note that this is just a suggestion, and the actual menu items may vary depending on the restaurant\\'s concept and offerings.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain,food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name','menu_items']\n",
    ")\n",
    "chain({'cuisine':'Arabian'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
